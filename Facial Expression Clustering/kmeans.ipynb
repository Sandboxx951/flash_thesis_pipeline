{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Video_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Video_ID'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m valid_hover_data \u001b[38;5;241m=\u001b[39m {col: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m hover_columns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m existing_columns}\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Extract the first video ID\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m video_id \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVideo_ID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Ensure \"Video ID\" column exists\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Update the figure title with the Video ID\u001b[39;00m\n\u001b[0;32m     53\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mscatter(\n\u001b[0;32m     54\u001b[0m     df_cleaned,\n\u001b[0;32m     55\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     labels\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom X Position\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAU Sum (Intensity)\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     61\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\alexa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Video_ID'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from itertools import chain\n",
    "import re\n",
    "\n",
    "\n",
    "file_path = \"face_aus_emotions_with_confidence.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to parse Active AUs column\n",
    "def parse_aus(au_str):\n",
    "    try:\n",
    "        matches = re.findall(r\"'(AU\\d+)': np\\.float64\\(([\\d.]+)\\)\", au_str)\n",
    "        return {au: float(value) for au, value in matches}\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# Clean Active AUs column\n",
    "df[\"Active AUs\"] = df[\"Active AUs\"].apply(parse_aus)\n",
    "\n",
    "# Remove rows with missing Predicted Emotion\n",
    "df_cleaned = df.dropna(subset=[\"Predicted Emotion\"]).copy()\n",
    "\n",
    "# Get all unique AUs for feature extraction\n",
    "all_aus = sorted(set(chain.from_iterable(df_cleaned[\"Active AUs\"].apply(lambda x: x.keys()))))\n",
    "\n",
    "# Convert Active AUs into feature vectors\n",
    "def vectorize_aus(au_dict, all_aus):\n",
    "    return [au_dict.get(au, 0.0) for au in all_aus]\n",
    "\n",
    "X = np.array(df_cleaned[\"Active AUs\"].apply(lambda x: vectorize_aus(x, all_aus)).tolist())\n",
    "\n",
    "# Compute AU Sum (Sum of all AU intensities per row)\n",
    "df_cleaned[\"AU Sum\"] = X.sum(axis=1)\n",
    "\n",
    "# Assign random X positions for visualization\n",
    "df_cleaned[\"X\"] = np.random.rand(len(df_cleaned)) * 100  \n",
    "df_cleaned[\"Y\"] = df_cleaned[\"AU Sum\"]  # Use AU Sum as Y-axis\n",
    "\n",
    "# Ensure columns used in hover_data exist\n",
    "existing_columns = df_cleaned.columns\n",
    "hover_columns = [\"Video ID\", \"Predicted Emotion\", \"Active AUs\", \"Confidence Level\"]\n",
    "valid_hover_data = {col: True for col in hover_columns if col in existing_columns}\n",
    "\n",
    "\n",
    "\n",
    "# Update the figure title with the Video ID\n",
    "fig = px.scatter(\n",
    "    df_cleaned,\n",
    "    x=\"X\",\n",
    "    y=\"Y\",\n",
    "    color=\"Predicted Emotion\",\n",
    "    hover_data=valid_hover_data,\n",
    "    title=f\"Interactive Clustering of AUs by Predicted Emotion (Video ID: {video_id})\",\n",
    "    labels={\"X\": \"Random X Position\", \"Y\": \"AU Sum (Intensity)\"},\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# **ðŸ“· Display Thumbnails for Each Predicted Emotion**\n",
    "thumbnail_folder = r\"C:\\Users\\alexa\\Thesis\\processed_thumbnails\"  # Adjust to your directory\n",
    "\n",
    "for emotion in df_cleaned[\"Predicted Emotion\"].unique():\n",
    "    emotion_images = df_cleaned[df_cleaned[\"Predicted Emotion\"] == emotion][\"Image Title\"].unique().tolist()\n",
    "    print(f\"Emotion '{emotion}': {len(emotion_images)} images\")\n",
    "\n",
    "    # Create a 10x10 grid (max 100 images per emotion)\n",
    "    fig, axes = plt.subplots(10, 10, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, img_title in enumerate(emotion_images[:100]):\n",
    "        img_path = os.path.join(thumbnail_folder, img_title)\n",
    "        if os.path.exists(img_path):\n",
    "            img = mpimg.imread(img_path)\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].axis(\"off\")\n",
    "            axes[i].set_title(img_title[:10], fontsize=8)  # Shorten title for better fit\n",
    "        else:\n",
    "            axes[i].axis(\"off\")\n",
    "            axes[i].set_title(\"Not Found\", fontsize=8)\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Emotional intensity clustering completed. Thumbnails displayed for each predicted emotion.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Silhouette Score: 0.9347 (Higher is better)\n",
      "ðŸ”¹ Davies-Bouldin Index: 0.4732 (Lower is better)\n",
      "\n",
      "ðŸ“Š Cluster Sizes:\n",
      "Cluster\n",
      "0    2237\n",
      "1      10\n",
      "2       4\n",
      "4       3\n",
      "3       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from itertools import chain\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"face_aus_emotions_with_confidence.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to parse Active AUs column\n",
    "def parse_aus(au_str):\n",
    "    try:\n",
    "        matches = re.findall(r\"'(AU\\d+)': np\\.float64\\(([\\d.]+)\\)\", au_str)\n",
    "        return {au: float(value) for au, value in matches}\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "# Clean Active AUs column\n",
    "df[\"Active AUs\"] = df[\"Active AUs\"].apply(parse_aus)\n",
    "\n",
    "# Remove rows with missing Predicted Emotion\n",
    "df_cleaned = df.dropna(subset=[\"Predicted Emotion\"]).copy()\n",
    "\n",
    "# Get all unique AUs for feature extraction\n",
    "all_aus = sorted(set(chain.from_iterable(df_cleaned[\"Active AUs\"].apply(lambda x: x.keys()))))\n",
    "\n",
    "# Convert Active AUs into feature vectors\n",
    "def vectorize_aus(au_dict, all_aus):\n",
    "    return [au_dict.get(au, 0.0) for au in all_aus]\n",
    "\n",
    "X = np.array(df_cleaned[\"Active AUs\"].apply(lambda x: vectorize_aus(x, all_aus)).tolist())\n",
    "\n",
    "# Compute AU Sum (Sum of all AU intensities per row)\n",
    "df_cleaned[\"AU Sum\"] = X.sum(axis=1)\n",
    "\n",
    "# Apply K-Means clustering (5 clusters)\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "df_cleaned[\"Cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# Evaluate Clusters\n",
    "silhouette_avg = silhouette_score(X, df_cleaned[\"Cluster\"])\n",
    "davies_bouldin_avg = davies_bouldin_score(X, df_cleaned[\"Cluster\"])\n",
    "\n",
    "# Display results\n",
    "print(f\"ðŸ”¹ Silhouette Score: {silhouette_avg:.4f} (Higher is better)\")\n",
    "print(f\"ðŸ”¹ Davies-Bouldin Index: {davies_bouldin_avg:.4f} (Lower is better)\")\n",
    "\n",
    "# Optional: Show Cluster Sizes\n",
    "print(\"\\nðŸ“Š Cluster Sizes:\")\n",
    "print(df_cleaned[\"Cluster\"].value_counts())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
